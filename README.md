The present architectural design employs basic LSTM processing that has one layer alongside a dropout parameter value set at 0.4. 
The current model design works sufficiently yet creates new possibilities to investigate advanced architecture structures. 
The training dataset becomes more robust through the implementation of strategies which include synonym replacement and back-translation. 
The text classification performance increases substantially through techniques which Wei and Zou (2019) 
introduced in their Easy Data Augmentation (EDA) research indicating similar performance gains for text generation.
